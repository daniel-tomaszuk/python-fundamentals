{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project you have 4 files containing information about persons.\n",
    "\n",
    "The files are:\n",
    "* `personal_info.csv` -   personal information such as name, gender, etc. (one row per person)\n",
    "* `vehicles.csv` -   what vehicle people own (one row per person)\n",
    "* `employment.csv` -   where a person is employed (one row per person)\n",
    "* `update_status.csv` -   when the person's data was created and last updated\n",
    "\n",
    "Each file contains a key, `SSN`, which **uniquely** identifies a person.\n",
    "\n",
    "This key is present in **all** four files.\n",
    "\n",
    "You are guaranteed that the same SSN value is present in **every** file, and that it only appears **once per file**.\n",
    "\n",
    "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 1\n",
    "\n",
    "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
    "\n",
    "For now these four iterators are just separate, independent iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 2\n",
    "\n",
    "Create a single iterable that combines all the columns from all the iterators.\n",
    "\n",
    "The iterable should yield named tuples containing all the columns.\n",
    "\n",
    "Normally you should ensure that the SSN's match across all the files (i.e. identical row numbers in each file refer to the same SSN). However, in this case you do not need to do so as the data is already \"aligned\" - all the files are guaranteed to be in SSN sort order, every SSN is unique, and every SSN appears in every file.\n",
    "\n",
    "Just make sure that in your iterable the SSN is not repeated 4 times - one time per row is enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 3\n",
    "\n",
    "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the `last_updated` field from the `status_update` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Goal 4\n",
    "\n",
    "Find the largest group of car makes for each gender.\n",
    "\n",
    "Possibly more than one such group per gender exists (equal sizes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "#### Hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will not be able to use a simple split approach here, as I explain in the video.\n",
    "\n",
    "Instead you should use the `csv` module and the `reader` function.\n",
    "\n",
    "Here's a simple example of how to use it - you will need to expand on this for your project goals, but this is a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        rows = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        yield from rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ssn', 'first_name', 'last_name', 'gender', 'language']\n",
      "['100-53-9824', 'Sebastiano', 'Tester', 'Male', 'Icelandic']\n",
      "['101-71-4702', 'Cayla', 'MacDonagh', 'Female', 'Lao']\n",
      "['101-84-0356', 'Nomi', 'Lipprose', 'Female', 'Yiddish']\n",
      "['104-22-0928', 'Justinian', 'Kunzelmann', 'Male', 'Dhivehi']\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "rows = read_file('personal_info.csv')\n",
    "for row in islice(rows, 5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data is already separated into a list containing the individual fields - but of course they are all just strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal 1\n",
    "```\n",
    "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
    "\n",
    "For now these four iterators are just separate, independent iterators.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "from collections import namedtuple\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "class FileReader:\n",
    "    \"\"\"\n",
    "    General purpose csv file reader with basic item type validation.\n",
    "    Will try to cast into `int`, `datetime` (iso format) or `str`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_name: str = \"\"):\n",
    "        self._file_name = file_name\n",
    "        self._file_reader = self._read_file()\n",
    "\n",
    "        # I'm making some file name asumptions, parsing file name isn't a point of this excercies\n",
    "        headers = next(self._file_reader)\n",
    "        self._row_factory = namedtuple(file_name.split(\".\")[0].title().replace(\"_\", \"\"), headers)\n",
    "    \n",
    "    @property\n",
    "    def file_name(self):\n",
    "        return self._file_name\n",
    "\n",
    "    @property\n",
    "    def fields(self):\n",
    "        return self._row_factory._fields\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        row = next(self._file_reader)\n",
    "        row = self._cast_row_types(row)   \n",
    "        return self._row_factory(*row)\n",
    "\n",
    "    def _read_file(self):\n",
    "        with open(self.file_name) as f:\n",
    "            rows = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "            yield from rows\n",
    "\n",
    "    def _cast_row_types(self, row: str):\n",
    "        row_updated_types = []\n",
    "        for el in row:\n",
    "            try:\n",
    "                el: datetime.datetime = datetime.fromisoformat(el)\n",
    "                row_updated_types.append(el)\n",
    "                continue\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "            if el.isdigit():\n",
    "                row_updated_types.append(int(el))\n",
    "            else:\n",
    "                row_updated_types.append(str(el))\n",
    "\n",
    "        return row_updated_types\n",
    "        \n",
    "\n",
    "\n",
    "PersonalInfoReader = FileReader(\"personal_info.csv\")\n",
    "EmploymentInfoReader = FileReader(\"employment.csv\")\n",
    "VehicleInfoReader = FileReader(\"vehicles.csv\")\n",
    "UpdateStatusInfoReader = FileReader(\"update_status.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PersonalInfo(ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
      "\n",
      "PersonalInfo(ssn='101-71-4702', first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
      "\n",
      "PersonalInfo(ssn='101-84-0356', first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n",
      "\n",
      "PersonalInfo(ssn='104-22-0928', first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi')\n",
      "\n",
      "PersonalInfo(ssn='104-84-7144', first_name='Claudianus', last_name='Brixey', gender='Male', language='Afrikaans')\n",
      "\n",
      "Employment(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824')\n",
      "\n",
      "Employment(employer='Nicolas and Sons', department='Sales', employee_id='41-6841359', ssn='101-71-4702')\n",
      "\n",
      "Employment(employer='Connelly Group', department='Research and Development', employee_id='98-7952860', ssn='101-84-0356')\n",
      "\n",
      "Employment(employer='Upton LLC', department='Marketing', employee_id='56-9817552', ssn='104-22-0928')\n",
      "\n",
      "Employment(employer='Zemlak-Olson', department='Business Development', employee_id='46-2886707', ssn='104-84-7144')\n",
      "\n",
      "Vehicles(ssn='100-53-9824', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)\n",
      "\n",
      "Vehicles(ssn='101-71-4702', vehicle_make='Ford', vehicle_model='Mustang', model_year=1997)\n",
      "\n",
      "Vehicles(ssn='101-84-0356', vehicle_make='GMC', vehicle_model='Yukon', model_year=2005)\n",
      "\n",
      "Vehicles(ssn='104-22-0928', vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000)\n",
      "\n",
      "Vehicles(ssn='104-84-7144', vehicle_make='Ford', vehicle_model='Crown Victoria', model_year=2008)\n",
      "\n",
      "UpdateStatus(ssn='100-53-9824', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42, tzinfo=datetime.timezone.utc), created=datetime.datetime(2016, 1, 24, 21, 19, 30, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "UpdateStatus(ssn='101-71-4702', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17, tzinfo=datetime.timezone.utc), created=datetime.datetime(2016, 1, 27, 4, 32, 57, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "UpdateStatus(ssn='101-84-0356', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30, tzinfo=datetime.timezone.utc), created=datetime.datetime(2016, 9, 21, 23, 4, 7, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "UpdateStatus(ssn='104-22-0928', last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29, tzinfo=datetime.timezone.utc), created=datetime.datetime(2016, 4, 15, 11, 37, 17, tzinfo=datetime.timezone.utc))\n",
      "\n",
      "UpdateStatus(ssn='104-84-7144', last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33, tzinfo=datetime.timezone.utc), created=datetime.datetime(2016, 3, 15, 14, 7, 57, tzinfo=datetime.timezone.utc))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain, islice\n",
    "\n",
    "\n",
    "file_readers = chain(\n",
    "    islice(PersonalInfoReader, 0, 5), \n",
    "    islice(EmploymentInfoReader, 0, 5), \n",
    "    islice(VehicleInfoReader, 0, 5), \n",
    "    islice(UpdateStatusInfoReader, 0, 5),\n",
    ")\n",
    "\n",
    "for fr in file_readers:\n",
    "    print(fr)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal 2\n",
    "Create a single iterable that combines all the columns from all the iterators.\n",
    "\n",
    "The iterable should yield named tuples containing all the columns.\n",
    "\n",
    "Normally you should ensure that the SSN's match across all the files (i.e. identical row numbers in each file refer to the same SSN). However, in this case you do not need to do so as the data is already \"aligned\" - all the files are guaranteed to be in SSN sort order, every SSN is unique, and every SSN appears in every file.\n",
    "\n",
    "Just make sure that in your iterable the SSN is not repeated 4 times - one time per row is enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataRow(employee_id='29-0890771', vehicle_model='Bravada', first_name='Sebastiano', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42, tzinfo=datetime.timezone.utc), ssn='100-53-9824', department='Research and Development', created=datetime.datetime(2016, 1, 24, 21, 19, 30, tzinfo=datetime.timezone.utc), employer='Stiedemann-Bailey', vehicle_make='Oldsmobile', model_year=1993, gender='Male', last_name='Tester', language='Icelandic')\n",
      "\n",
      "DataRow(employee_id='41-6841359', vehicle_model='Mustang', first_name='Cayla', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17, tzinfo=datetime.timezone.utc), ssn='101-71-4702', department='Sales', created=datetime.datetime(2016, 1, 27, 4, 32, 57, tzinfo=datetime.timezone.utc), employer='Nicolas and Sons', vehicle_make='Ford', model_year=1997, gender='Female', last_name='MacDonagh', language='Lao')\n",
      "\n",
      "DataRow(employee_id='98-7952860', vehicle_model='Yukon', first_name='Nomi', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30, tzinfo=datetime.timezone.utc), ssn='101-84-0356', department='Research and Development', created=datetime.datetime(2016, 9, 21, 23, 4, 7, tzinfo=datetime.timezone.utc), employer='Connelly Group', vehicle_make='GMC', model_year=2005, gender='Female', last_name='Lipprose', language='Yiddish')\n",
      "\n",
      "DataRow(employee_id='56-9817552', vehicle_model='Intrigue', first_name='Justinian', last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29, tzinfo=datetime.timezone.utc), ssn='104-22-0928', department='Marketing', created=datetime.datetime(2016, 4, 15, 11, 37, 17, tzinfo=datetime.timezone.utc), employer='Upton LLC', vehicle_make='Oldsmobile', model_year=2000, gender='Male', last_name='Kunzelmann', language='Dhivehi')\n",
      "\n",
      "DataRow(employee_id='46-2886707', vehicle_model='Crown Victoria', first_name='Claudianus', last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33, tzinfo=datetime.timezone.utc), ssn='104-84-7144', department='Business Development', created=datetime.datetime(2016, 3, 15, 14, 7, 57, tzinfo=datetime.timezone.utc), employer='Zemlak-Olson', vehicle_make='Ford', model_year=2008, gender='Male', last_name='Brixey', language='Afrikaans')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PersonalInfoReader = FileReader(\"personal_info.csv\")\n",
    "EmploymentInfoReader = FileReader(\"employment.csv\")\n",
    "VehicleInfoReader = FileReader(\"vehicles.csv\")\n",
    "UpdateStatusInfoReader = FileReader(\"update_status.csv\")\n",
    "\n",
    "combined_data_row = set(field for reader in (PersonalInfoReader, EmploymentInfoReader, VehicleInfoReader, UpdateStatusInfoReader) for field in reader.fields)\n",
    "DataRow = namedtuple(\"DataRow\", \",\".join(combined_data_row))\n",
    "\n",
    "\n",
    "def person_data():\n",
    "    for _ in range(5):\n",
    "        # data is presorted so it's fine - IDs (SSN) will match on order alone\n",
    "        row_data = {\n",
    "            **(next(PersonalInfoReader))._asdict(),\n",
    "            **(next(EmploymentInfoReader))._asdict(),\n",
    "            **(next(VehicleInfoReader))._asdict(),\n",
    "            **(next(UpdateStatusInfoReader))._asdict(),\n",
    "        }\n",
    "        yield DataRow(**row_data)\n",
    "\n",
    "\n",
    "for d in person_data():\n",
    "    print(d)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal 3\n",
    "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the last_updated field from the status_update file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataRow(employee_id='82-2230506', vehicle_model='Sunfire', first_name='Clay', last_updated=datetime.datetime(2018, 3, 26, 6, 15, 57, tzinfo=datetime.timezone.utc), ssn='230-48-0684', department='Product Management', created=datetime.datetime(2016, 12, 29, 6, 0, 3, tzinfo=datetime.timezone.utc), employer='Fahey Group', vehicle_make='Pontiac', model_year=1999, gender='Male', last_name='Peaurt', language='Dhivehi')\n",
      "\n",
      "DataRow(employee_id='99-0856844', vehicle_model='CC', first_name='Markus', last_updated=datetime.datetime(2017, 8, 10, 19, 34, 42, tzinfo=datetime.timezone.utc), ssn='230-99-1485', department='Marketing', created=datetime.datetime(2016, 9, 19, 22, 26, 22, tzinfo=datetime.timezone.utc), employer='Hodkiewicz-Murray', vehicle_make='Volkswagen', model_year=2009, gender='Male', last_name='Revill', language='Moldovan')\n",
      "\n",
      "DataRow(employee_id='68-3132488', vehicle_model='Sonoma Club Coupe', first_name='Gisele', last_updated=datetime.datetime(2017, 4, 7, 22, 50, 50, tzinfo=datetime.timezone.utc), ssn='231-66-9264', department='Marketing', created=datetime.datetime(2016, 6, 1, 8, 10, 38, tzinfo=datetime.timezone.utc), employer='Dare, Kuhn and Pfannerstill', vehicle_make='GMC', model_year=1994, gender='Female', last_name='Castelow', language='Hiri Motu')\n",
      "\n",
      "DataRow(employee_id='02-4952668', vehicle_model='Samurai', first_name='Clare', last_updated=datetime.datetime(2017, 9, 23, 2, 16, 56, tzinfo=datetime.timezone.utc), ssn='232-18-5397', department='Legal', created=datetime.datetime(2016, 2, 20, 4, 33, 2, tzinfo=datetime.timezone.utc), employer=\"Schumm-O'Conner\", vehicle_make='Suzuki', model_year=1995, gender='Female', last_name='McGairl', language='Bengali')\n",
      "\n",
      "DataRow(employee_id='38-0287814', vehicle_model='Firebird', first_name='Arlyne', last_updated=datetime.datetime(2018, 1, 31, 9, 38, 49, tzinfo=datetime.timezone.utc), ssn='233-27-2377', department='Marketing', created=datetime.datetime(2016, 2, 13, 21, 32, 41, tzinfo=datetime.timezone.utc), employer='Donnelly, Abernathy and Blanda', vehicle_make='Pontiac', model_year=1986, gender='Female', last_name='Stenning', language='Dari')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recently_updated_person_data():\n",
    "    PersonalInfoReader = FileReader(\"personal_info.csv\")\n",
    "    EmploymentInfoReader = FileReader(\"employment.csv\")\n",
    "    VehicleInfoReader = FileReader(\"vehicles.csv\")\n",
    "    UpdateStatusInfoReader = FileReader(\"update_status.csv\")\n",
    "    combined_data_row = set(\n",
    "        field \n",
    "        for reader in (PersonalInfoReader, EmploymentInfoReader, VehicleInfoReader, UpdateStatusInfoReader) \n",
    "        for field in reader.fields\n",
    "    )\n",
    "    DataRow = namedtuple(\"DataRow\", \",\".join(combined_data_row))\n",
    "\n",
    "    cut_out_date = datetime(2017, 3, 1, tzinfo=timezone.utc)\n",
    "    while True:\n",
    "        update_status = next(UpdateStatusInfoReader, None)\n",
    "        if not update_status:\n",
    "            return \n",
    "\n",
    "        # takewhile / dropwhile could be used\n",
    "        while update_status.last_updated <= cut_out_date:\n",
    "            next(PersonalInfoReader)\n",
    "            next(EmploymentInfoReader)\n",
    "            next(VehicleInfoReader)\n",
    "            update_status = next(UpdateStatusInfoReader, None)\n",
    "            if not update_status:\n",
    "                return \n",
    "\n",
    "        row_data = {\n",
    "            **(next(PersonalInfoReader))._asdict(),\n",
    "            **(next(EmploymentInfoReader))._asdict(),\n",
    "            **(next(VehicleInfoReader))._asdict(),\n",
    "            **(update_status)._asdict(),\n",
    "        }\n",
    "        yield DataRow(**row_data)\n",
    "\n",
    "for d in itertools.islice(recently_updated_person_data(), 150, 155):\n",
    "    print(d)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal 4\n",
    "Find the largest group of car makes for each gender.\n",
    "\n",
    "Possibly more than one such group per gender exists (equal sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Female', 'Chevrolet'), 42)\n",
      "(('Female', 'Ford'), 42)\n",
      "(('Male', 'Ford'), 40)\n",
      "(('Male', 'Chevrolet'), 30)\n",
      "(('Male', 'GMC'), 28)\n",
      "(('Male', 'Mitsubishi'), 28)\n",
      "(('Female', 'GMC'), 22)\n",
      "(('Female', 'Mitsubishi'), 22)\n",
      "(('Male', 'Dodge'), 22)\n",
      "(('Male', 'Toyota'), 21)\n",
      "(('Female', 'Toyota'), 20)\n",
      "(('Male', 'Mercedes-Benz'), 19)\n",
      "(('Female', 'Dodge'), 17)\n",
      "(('Female', 'Mercedes-Benz'), 17)\n",
      "(('Male', 'Volkswagen'), 16)\n",
      "(('Female', 'Lexus'), 15)\n",
      "(('Female', 'Pontiac'), 14)\n",
      "(('Male', 'Audi'), 14)\n",
      "(('Female', 'Audi'), 13)\n",
      "(('Female', 'Mazda'), 13)\n",
      "(('Female', 'Volvo'), 13)\n",
      "(('Male', 'Buick'), 13)\n",
      "(('Male', 'Mazda'), 13)\n",
      "(('Female', 'BMW'), 12)\n",
      "(('Female', 'Nissan'), 12)\n",
      "(('Female', 'Suzuki'), 12)\n",
      "(('Male', 'BMW'), 12)\n",
      "(('Female', 'Buick'), 11)\n",
      "(('Male', 'Mercury'), 11)\n",
      "(('Male', 'Pontiac'), 11)\n",
      "(('Female', 'Volkswagen'), 10)\n",
      "(('Male', 'Volvo'), 10)\n",
      "(('Female', 'Acura'), 9)\n",
      "(('Female', 'Infiniti'), 9)\n",
      "(('Female', 'Kia'), 9)\n",
      "(('Male', 'Cadillac'), 9)\n",
      "(('Male', 'Honda'), 9)\n",
      "(('Female', 'Honda'), 8)\n",
      "(('Female', 'Land Rover'), 8)\n",
      "(('Female', 'Oldsmobile'), 8)\n",
      "(('Male', 'Hyundai'), 8)\n",
      "(('Male', 'Saab'), 8)\n",
      "(('Male', 'Subaru'), 8)\n",
      "(('Male', 'Acura'), 7)\n",
      "(('Male', 'Infiniti'), 7)\n",
      "(('Male', 'Jeep'), 7)\n",
      "(('Female', 'Cadillac'), 6)\n",
      "(('Female', 'Chrysler'), 6)\n",
      "(('Female', 'Subaru'), 6)\n",
      "(('Male', 'Lexus'), 6)\n",
      "(('Male', 'Nissan'), 6)\n",
      "(('Female', 'Jeep'), 5)\n",
      "(('Female', 'Lotus'), 5)\n",
      "(('Female', 'Mercury'), 5)\n",
      "(('Male', 'Kia'), 5)\n",
      "(('Male', 'Lincoln'), 5)\n",
      "(('Male', 'Lotus'), 5)\n",
      "(('Male', 'Oldsmobile'), 5)\n",
      "(('Female', 'Bentley'), 4)\n",
      "(('Female', 'Hyundai'), 4)\n",
      "(('Female', 'Lincoln'), 4)\n",
      "(('Male', 'Jaguar'), 4)\n",
      "(('Male', 'Lamborghini'), 4)\n",
      "(('Male', 'Plymouth'), 4)\n",
      "(('Male', 'Porsche'), 4)\n",
      "(('Female', 'Isuzu'), 3)\n",
      "(('Female', 'Jaguar'), 3)\n",
      "(('Female', 'Plymouth'), 3)\n",
      "(('Female', 'Porsche'), 3)\n",
      "(('Female', 'Saab'), 3)\n",
      "(('Female', 'Saturn'), 3)\n",
      "(('Male', 'Aston Martin'), 3)\n",
      "(('Male', 'Bentley'), 3)\n",
      "(('Male', 'Chrysler'), 3)\n",
      "(('Male', 'Isuzu'), 3)\n",
      "(('Male', 'Land Rover'), 3)\n",
      "(('Male', 'Maserati'), 3)\n",
      "(('Male', 'Saturn'), 3)\n",
      "(('Female', 'Aston Martin'), 2)\n",
      "(('Female', 'Lamborghini'), 2)\n",
      "(('Female', 'Scion'), 2)\n",
      "(('Male', 'Geo'), 2)\n",
      "(('Male', 'Maybach'), 2)\n",
      "(('Male', 'Panoz'), 2)\n",
      "(('Male', 'Suzuki'), 2)\n",
      "(('Female', 'Austin'), 1)\n",
      "(('Female', 'Bugatti'), 1)\n",
      "(('Female', 'Eagle'), 1)\n",
      "(('Female', 'Geo'), 1)\n",
      "(('Female', 'Morgan'), 1)\n",
      "(('Female', 'Panoz'), 1)\n",
      "(('Female', 'Rolls-Royce'), 1)\n",
      "(('Male', 'Aptera'), 1)\n",
      "(('Male', 'Austin'), 1)\n",
      "(('Male', 'Corbin'), 1)\n",
      "(('Male', 'Daewoo'), 1)\n",
      "(('Male', 'Eagle'), 1)\n",
      "(('Male', 'Jensen'), 1)\n",
      "(('Male', 'Rolls-Royce'), 1)\n",
      "(('Male', 'Scion'), 1)\n",
      "(('Male', 'Smart'), 1)\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "from itertools import groupby\n",
    "\n",
    "grouping_key = lambda data_row: (data_row.gender, data_row.vehicle_make)\n",
    "\n",
    "# before grouping, we need to sort the data so duplicated groups are not created\n",
    "recently_updated = sorted(recently_updated_person_data(), key=grouping_key)\n",
    "groups = groupby(recently_updated, key=grouping_key)\n",
    "\n",
    "genders_and_makes = []\n",
    "for gender_and_make, make_list in groups:\n",
    "    genders_and_makes.append((gender_and_make, len(list(make_list))))\n",
    "\n",
    "for row in sorted(genders_and_makes, key=lambda x: x[1], reverse=True):\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
